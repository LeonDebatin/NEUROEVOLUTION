{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gpolnel'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TensorDataset, DataLoader\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgpolnel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproblems\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minductive_programming\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SML\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgpolnel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgpolnel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mffunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Ffunctions\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gpolnel'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import pickle\n",
    "from gpolnel.problems.inductive_programming import SML\n",
    "from gpolnel.utils.utils import train_test_split\n",
    "from gpolnel.utils.ffunctions import Ffunctions\n",
    "from gpolnel.utils.inductive_programming import function_map\n",
    "from gpolnel.algorithms.genetic_algorithm import GeneticAlgorithm\n",
    "from gpolnel.operators.initializers import grow, prm_grow, ERC\n",
    "from gpolnel.operators.variators import swap_xo, prm_subtree_mtn\n",
    "from gpolnel.operators.selectors import prm_tournament, roulette_wheel, rank_selection\n",
    "from gpolnel.utils.inductive_programming import _execute_tree\n",
    "seed=1\n",
    "random.seed(seed)\n",
    "import numpy as np\n",
    "parent_dir = os.path.abspath(os.path.join(os.path.dirname('../NEUROEVOLUTION'), '..'))\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(0, parent_dir)\n",
    "\n",
    "from utils import kfold\n",
    "from utils import drop_features\n",
    "from utils import scale\n",
    "from utils import clipp\n",
    "from utils import cv_logger_init\n",
    "from utils import cv_logger_append\n",
    "from utils import device\n",
    "#_evaluate_individual_ffunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# def evaluate_solution(mheuristic, X_test, y_test):\n",
    "#     y_pred = np.float(_execute_tree(mheuristic.best_sol.repr_, X_test))\n",
    "#     return mean_squared_error(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = torch.tensor(pd.read_csv('datamart/X_train_clipped.csv').values)\n",
    "# X_test = torch.tensor(pd.read_csv('datamart/X_test_clipped.csv').values)\n",
    "# y_train = torch.tensor(pd.read_csv('datamart/y_lactose_train.csv')['lactose_percent'].values)\n",
    "# y_test = torch.tensor(pd.read_csv('datamart/y_lactose_test.csv')['lactose_percent'].values)\n",
    "X = pd.read_csv('datamart/data_project_nel.csv')\n",
    "y = pd.read_csv('datamart/y_lactose.csv')['lactose_percent']\n",
    "X = drop_features(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fset = [function_map['add'],  function_map['sub']]#function_map['sub'],\n",
    "total_batches = 1\n",
    "batch_size = X.shape[0]\n",
    "sspace_sml = {\n",
    "    'n_dims': X.shape[1],\n",
    "    'function_set': fset, 'constant_set': ERC(-5., 5.),\n",
    "    'p_constants': 0.1,\n",
    "    'max_init_depth': 3,\n",
    "    'max_depth': 5, \n",
    "    'n_batches': total_batches,\n",
    "    'device': device\n",
    "}\n",
    "\n",
    "ps =  100\n",
    "selection_pressure = .1\n",
    "mutation_prob = .7\n",
    "xo_prob = .9\n",
    "has_elitism = True\n",
    "allow_reproduction = False\n",
    "ffunction = Ffunctions('rmse')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle= True\n",
    "total_batches = 1\n",
    "batch_size = X.shape[0]\n",
    "# Creates training and validatation data sets\n",
    "# X = torch.tensor(X.values)\n",
    "# y = torch.tensor(y.values)\n",
    "# ds_train = TensorDataset(X, y)\n",
    "# ds_test = TensorDataset(X, y)\n",
    "\n",
    "# Creates training and test data loaders\n",
    "# dl_train = DataLoader(ds_train, batch_size, shuffle)\n",
    "# dl_test = DataLoader(ds_test, batch_size, shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gp_train(dl_train, dl_val, ps, sspace_sml, ffunction, log_path, selection_pressure, mutation_prob, xo_prob, has_elitism, allow_reproduction, seed=1, n_iter=3000, device='cpu',save_model=False, log=1, id=None):\n",
    "\n",
    "    pi_sml = SML(\n",
    "        sspace=sspace_sml,\n",
    "        ffunction=ffunction,\n",
    "        dl_train=dl_train, dl_test=dl_val,  # For the algorithm, the unseen is our validation!\n",
    "        n_jobs=8\n",
    "    )\n",
    "\n",
    "    mheuristic = GeneticAlgorithm(\n",
    "        pi=pi_sml,\n",
    "        initializer=grow,\n",
    "        selector=prm_tournament(pressure=selection_pressure),  #prm_tournament(pressure=selection_pressure)\n",
    "        crossover=swap_xo,\n",
    "        mutator=prm_subtree_mtn(initializer=prm_grow(sspace_sml)),\n",
    "        pop_size=ps,\n",
    "        p_m=mutation_prob,\n",
    "        p_c=xo_prob,\n",
    "        elitism=has_elitism,\n",
    "        reproduction=allow_reproduction,  # False = or xo or mutation\n",
    "        device=device,\n",
    "        seed=seed\n",
    "    )\n",
    "    mheuristic._initialize()\n",
    "\n",
    "    mheuristic.solve(\n",
    "        n_iter,\n",
    "        verbose=0, log=log, log_path=log_path,\n",
    "        test_elite=True\n",
    "    )\n",
    "    \n",
    "    \n",
    "    return mheuristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = gp_train(dl_train = dl_train, dl_val = dl_test, ps=ps, sspace_sml = sspace_sml, ffunction=ffunction, log_path='abc.csv',  selection_pressure=0.05, mutation_prob=0.2, xo_prob=0.8, has_elitism=True, allow_reproduction=True, seed=1, n_iter=30, device='cpu')\n",
    "# m.best_sol.printTree()\n",
    "# m.best_sol.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gp_cross_validation(X, y, kf, ps, sspace_sml, ffunction, log_path_cv, log_path_train,  selection_pressure, mutation_prob, xo_prob, has_elitism, allow_reproduction, seed, n_iter, device, id=None, log=False):\n",
    "    results = []\n",
    "    feature_names = X.columns\n",
    "    \n",
    "    if log:\n",
    "        cv_logger_init(log_path_cv)\n",
    "            \n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(X)):\n",
    "        print(type(X))\n",
    "        X_train, X_val = X.loc[train_index], X.loc[val_index]\n",
    "        y_train, y_val = y.loc[train_index], y.loc[val_index]\n",
    "        \n",
    "        print(type(X_train))\n",
    "        X_train, X_val = clipp(X_train, X_val)\n",
    "        X_train, X_val = scale(X_train, X_val)\n",
    "        \n",
    "        ds_train = TensorDataset(torch.tensor(X_train.values), torch.tensor(y_train.values))\n",
    "        ds_val = TensorDataset(torch.tensor(X_val.values), torch.tensor(y_val.values))\n",
    "\n",
    "        # Creates training and test data loaders\n",
    "        dl_train = DataLoader(ds_train, batch_size, shuffle)\n",
    "        dl_val = DataLoader(ds_val, batch_size, shuffle)\n",
    "\n",
    "        m = gp_train(dl_train = dl_train, dl_val = dl_val, ps=ps, sspace_sml = sspace_sml, ffunction=ffunction, log_path=log_path_train,  selection_pressure=selection_pressure, mutation_prob=mutation_prob, xo_prob=xo_prob, has_elitism=has_elitism, allow_reproduction=allow_reproduction,  seed=seed, n_iter=n_iter, device=device)\n",
    "        m.best_sol.printTree(feature_names=feature_names)\n",
    "        score = m.best_sol.fit\n",
    "        results.append(score)\n",
    "    \n",
    "        if log:\n",
    "            cv_logger_append(log_path_cv, id, fold, score)\n",
    "        \n",
    "    avg_score = np.mean(results)\n",
    "    print('cv_score:', avg_score)\n",
    "    \n",
    "    return avg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gp_cross_validation(X, y, kfold, ps=ps, sspace_sml = sspace_sml, ffunction = ffunction, log_path_cv='abc.csv', log_path_train='ttt.csv',  selection_pressure=0.05, mutation_prob=0.2, xo_prob=0.8, has_elitism=True, allow_reproduction=True, seed=1, n_iter=10, device='cpu', log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sub]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "4.8504\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "4.8504\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "4.8504\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "4.5296\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "sub( sub( rumination_min_day, rumination_min_day ) -4.8707 )\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "4.9277\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "sub( sub( high_cdt_by_100_milkings, high_cdt_by_100_milkings ) -4.8707 )\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "4.5833\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "4.9277\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "4.5296\n",
      "cv_score: 0.15679488\n",
      "0.15679488\n",
      "Iteration 0\n",
      "New best validation score: 0.15679487586021423\n",
      "[add]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "4.8941\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 54\u001b[0m\n\u001b[0;32m     42\u001b[0m log_path_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogs/GP/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_cv_train.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     44\u001b[0m sspace_sml \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_dims\u001b[39m\u001b[38;5;124m'\u001b[39m: X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfunction_set\u001b[39m\u001b[38;5;124m'\u001b[39m: fset, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconstant_set\u001b[39m\u001b[38;5;124m'\u001b[39m: constant_set,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m: device\n\u001b[0;32m     52\u001b[0m }\n\u001b[1;32m---> 54\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mgp_cross_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkfold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msspace_sml\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msspace_sml\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mffunction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mffunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_path_cv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_path_cv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_path_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_path_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mselection_pressure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mselection_pressure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmutation_prob\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmutation_prob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxo_prob\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxo_prob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_elitism\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_elitism\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_reproduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_reproduction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(score)\n\u001b[0;32m     57\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogs/GP/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom_search_total\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "Cell \u001b[1;32mIn[8], line 24\u001b[0m, in \u001b[0;36mgp_cross_validation\u001b[1;34m(X, y, kf, ps, sspace_sml, ffunction, log_path_cv, log_path_train, selection_pressure, mutation_prob, xo_prob, has_elitism, allow_reproduction, seed, n_iter, device, id, log)\u001b[0m\n\u001b[0;32m     21\u001b[0m dl_train \u001b[38;5;241m=\u001b[39m DataLoader(ds_train, batch_size, shuffle)\n\u001b[0;32m     22\u001b[0m dl_val \u001b[38;5;241m=\u001b[39m DataLoader(ds_val, batch_size, shuffle)\n\u001b[1;32m---> 24\u001b[0m m \u001b[38;5;241m=\u001b[39m \u001b[43mgp_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdl_train\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdl_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdl_val\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdl_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msspace_sml\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msspace_sml\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mffunction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mffunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_path_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mselection_pressure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mselection_pressure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmutation_prob\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmutation_prob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxo_prob\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxo_prob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_elitism\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_elitism\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_reproduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_reproduction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m m\u001b[38;5;241m.\u001b[39mbest_sol\u001b[38;5;241m.\u001b[39mprintTree(feature_names\u001b[38;5;241m=\u001b[39mfeature_names)\n\u001b[0;32m     26\u001b[0m score \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39mbest_sol\u001b[38;5;241m.\u001b[39mfit\n",
      "Cell \u001b[1;32mIn[6], line 26\u001b[0m, in \u001b[0;36mgp_train\u001b[1;34m(dl_train, dl_val, ps, sspace_sml, ffunction, log_path, selection_pressure, mutation_prob, xo_prob, has_elitism, allow_reproduction, seed, n_iter, device, save_model, log, id)\u001b[0m\n\u001b[0;32m     10\u001b[0m mheuristic \u001b[38;5;241m=\u001b[39m GeneticAlgorithm(\n\u001b[0;32m     11\u001b[0m     pi\u001b[38;5;241m=\u001b[39mpi_sml,\n\u001b[0;32m     12\u001b[0m     initializer\u001b[38;5;241m=\u001b[39mgrow,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m     seed\u001b[38;5;241m=\u001b[39mseed\n\u001b[0;32m     23\u001b[0m )\n\u001b[0;32m     24\u001b[0m mheuristic\u001b[38;5;241m.\u001b[39m_initialize()\n\u001b[1;32m---> 26\u001b[0m \u001b[43mmheuristic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_elite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m     30\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mheuristic\n",
      "File \u001b[1;32mc:\\Users\\leond\\OneDrive\\Desktop\\NeuroEvolutionaryLearning\\Git\\NEUROEVOLUTION\\gpolnel\\algorithms\\genetic_algorithm.py:301\u001b[0m, in \u001b[0;36mGeneticAlgorithm.solve\u001b[1;34m(self, n_iter, tol, n_iter_tol, start_at, test_elite, verbose, log, log_path, log_xp)\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;66;03m# 2) 1)\u001b[39;00m\n\u001b[0;32m    300\u001b[0m offs_pop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mglobals\u001b[39m()[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpop\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m](offs_pop)\n\u001b[1;32m--> 301\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_pop\u001b[49m\u001b[43m(\u001b[49m\u001b[43moffs_pop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;66;03m# Overrides elites's information, if it was re-evaluated, and removes it from 'offsprings'\u001b[39;00m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_training:\n",
      "File \u001b[1;32mc:\\Users\\leond\\OneDrive\\Desktop\\NeuroEvolutionaryLearning\\Git\\NEUROEVOLUTION\\gpolnel\\problems\\inductive_programming.py:399\u001b[0m, in \u001b[0;36mSML.evaluate_pop\u001b[1;34m(self, pop)\u001b[0m\n\u001b[0;32m    397\u001b[0m pop\u001b[38;5;241m.\u001b[39mvalid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_feasible_pop(pop\u001b[38;5;241m.\u001b[39mrepr_)\n\u001b[0;32m    398\u001b[0m \u001b[38;5;66;03m# Assigns individuals fitness(es)\u001b[39;00m\n\u001b[1;32m--> 399\u001b[0m pop\u001b[38;5;241m.\u001b[39mfit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate_pop_ffunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mffunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;66;03m# Assigns the default fitness to invalid solutions in the population\u001b[39;00m\n\u001b[0;32m    401\u001b[0m pop_invalid \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39mtorch\u001b[38;5;241m.\u001b[39mtensor(pop\u001b[38;5;241m.\u001b[39mvalid)\n",
      "File \u001b[1;32mc:\\Users\\leond\\OneDrive\\Desktop\\NeuroEvolutionaryLearning\\Git\\NEUROEVOLUTION\\gpolnel\\problems\\inductive_programming.py:268\u001b[0m, in \u001b[0;36mSML._evaluate_pop_ffunction\u001b[1;34m(self, ffunction, pop)\u001b[0m\n\u001b[0;32m    265\u001b[0m X, y \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice), batch[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    267\u001b[0m \u001b[38;5;66;03m# For the current batch, iterates over the population to evaluate_pop each individual\u001b[39;00m\n\u001b[1;32m--> 268\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_execute_tree\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepr_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrepr_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepr_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    270\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\leond\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32mc:\\Users\\leond\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\leond\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1707\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fsets = [function_map['add'],  function_map['mul'], function_map['div'],function_map['sub']] #,  function_map['mean']]\n",
    "constant_sets = [ERC(-1., 1.), ERC(-5., 5.), ERC(-10., 10.)]\n",
    "pss = [50, 100, 250, 500, 1000]\n",
    "p_constantss = [0.05, 0.1, 0.2, 0.3]\n",
    "max_init_depths = [2, 3, 4, 5, 6]\n",
    "max_depths = [5, 6, 7, 8, 9]\n",
    "selection_pressures = [0.05, 0.1, 0.2, 0.3, 0.4]\n",
    "mutatuion_probs = [0.05, 0.1, 0.15, 0.2, 0.5]\n",
    "xo_probs = [0.05, 0.1, 0.15, 0.2, 0.5]\n",
    "has_elitisms = [True, False]\n",
    "allow_reproductions = [True, False]\n",
    "n_iters = [50, 100, 250, 500, 1000]\n",
    "ffunction = Ffunctions('rmse')\n",
    "\n",
    "best_score = np.inf\n",
    "\n",
    "name = 'logs/GP/' + 'random_search_total' + '.csv'\n",
    "with open(name, 'w', newline='\\n') as csvfile:\n",
    "    w = csv.writer(csvfile, delimiter=';')\n",
    "    w.writerow(['id']+['fset']+['constant_set']+['ps']+['p_constants']+['max_init_depth']+['max_depth']+['selection_pressure']+['mutation_prob']+['xo_prob']+['has_elitism']+['allow_reproduction']+['n_iter']+['score'])\n",
    "\n",
    "\n",
    "for i in range(200):\n",
    "\n",
    "    total_batches = 1\n",
    "    batch_size = X.shape[0]\n",
    "    \n",
    "    fset = random.sample(fsets, random.randint(1, len(fsets)))\n",
    "    print(fset)\n",
    "    constant_set = random.choice(constant_sets)\n",
    "    ps = random.choice(pss)\n",
    "    p_constants = random.choice(p_constantss)\n",
    "    max_init_depth = random.choice(max_init_depths)\n",
    "    max_depth = random.choice(max_depths)\n",
    "    selection_pressure = random.choice(selection_pressures)\n",
    "    mutation_prob = random.choice(mutatuion_probs)\n",
    "    xo_prob = random.choice(xo_probs)\n",
    "    has_elitism = random.choice(has_elitisms)\n",
    "    allow_reproduction = random.choice(allow_reproductions)\n",
    "    n_iter = random.choice(n_iters)\n",
    "    log_path_cv = 'logs/GP/' + f'{i}' + '_cv_results.csv'\n",
    "    log_path_train = 'logs/GP/' + f'{i}' + '_cv_train.csv'\n",
    "\n",
    "    sspace_sml = {\n",
    "        'n_dims': X.shape[1],\n",
    "        'function_set': fset, 'constant_set': constant_set,\n",
    "        'p_constants': p_constants,\n",
    "        'max_init_depth': max_init_depth,\n",
    "        'max_depth': max_depth, \n",
    "        'n_batches': total_batches,\n",
    "        'device': device\n",
    "    }\n",
    "    \n",
    "    score = gp_cross_validation(X, y, kfold, ps=ps, sspace_sml = sspace_sml, ffunction=ffunction, log_path_cv=log_path_cv, log_path_train=log_path_train,  selection_pressure=selection_pressure, mutation_prob=mutation_prob, xo_prob=xo_prob, has_elitism=has_elitism, allow_reproduction=allow_reproduction, seed=1, n_iter=n_iter, device='cpu')\n",
    "    print(score)\n",
    "    \n",
    "    name = 'logs/GP/' + 'random_search_total' + '.csv'\n",
    "    with open(name, 'a', newline='\\n') as csvfile:\n",
    "        w = csv.writer(csvfile, delimiter=';')\n",
    "        w.writerow([i]+[fset]+[constant_set]+[ps]+[p_constants]+[max_init_depth]+[max_depth]+[selection_pressure]+[mutation_prob]+[xo_prob]+[has_elitism]+[allow_reproduction]+[n_iter]+[score])\n",
    "    \n",
    "    if score < best_score:\n",
    "        best_score = score\n",
    "        print('Iteration '+ str(i))\n",
    "        print(f'New best validation score: {best_score}')\n",
    "        best_params = [fset, constant_set, ps, p_constants, max_init_depth, max_depth, selection_pressure, mutation_prob, xo_prob, has_elitism, allow_reproduction, n_iter]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[sub],\n",
       " <gpolnel.operators.initializers.ERC at 0x18cff9f8a10>,\n",
       " 100,\n",
       " 0.05,\n",
       " 4,\n",
       " 5,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.5,\n",
       " True,\n",
       " False,\n",
       " 100]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
