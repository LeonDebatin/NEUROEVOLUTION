{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import csv\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "from gpolnel.utils.datasets import load_boston\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import pickle\n",
    "from gpolnel.problems.inductive_programming import SML\n",
    "from gpolnel.utils.utils import train_test_split\n",
    "from gpolnel.utils.ffunctions import Ffunctions\n",
    "from gpolnel.utils.inductive_programming import function_map\n",
    "from gpolnel.algorithms.genetic_algorithm import GeneticAlgorithm\n",
    "from gpolnel.operators.initializers import grow, prm_grow, ERC\n",
    "from gpolnel.operators.variators import swap_xo, prm_subtree_mtn\n",
    "from gpolnel.operators.selectors import prm_tournament, roulette_wheel, rank_selection\n",
    "from gpolnel.utils.inductive_programming import _execute_tree\n",
    "seed=1\n",
    "random.seed(seed)\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#_evaluate_individual_ffunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def evaluate_solution( mheuristic, X_test, y_test):\n",
    "    return mean_squared_error(_execute_tree(mheuristic.best_sol.repr_, X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(pd.read_csv('datamart/X_train_clipped.csv').values)\n",
    "X_test = torch.tensor(pd.read_csv('datamart/X_test_clipped.csv').values)\n",
    "y_train = torch.tensor(pd.read_csv('datamart/y_lactose_train.csv')['lactose_percent'].values)\n",
    "y_test = torch.tensor(pd.read_csv('datamart/y_lactose_test.csv')['lactose_percent'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fset = [function_map['add'],  function_map['mul'], function_map['div'],function_map['sub']]#function_map['sub'],\n",
    "total_batches = 1\n",
    "batch_size = X_train.shape[0]\n",
    "sspace_sml = {\n",
    "    'n_dims': X_train.shape[1],\n",
    "    'function_set': fset, 'constant_set': ERC(-5., 5.),\n",
    "    'p_constants': 0.1,\n",
    "    'max_init_depth': 3,\n",
    "    'max_depth': 5, \n",
    "    'n_batches': total_batches,\n",
    "    'device': device\n",
    "}\n",
    "\n",
    "ps = 50\n",
    "selection_pressure = .1\n",
    "mutation_prob = .7\n",
    "xo_prob = .9\n",
    "has_elitism = True\n",
    "allow_reproduction = False\n",
    "ffunction = Ffunctions('rmse')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle= True\n",
    "total_batches = 1\n",
    "batch_size = X_train.shape[0]\n",
    "# Creates training and validatation data sets\n",
    "ds_train = TensorDataset(X_train, y_train)\n",
    "ds_test = TensorDataset(X_test, y_test)\n",
    "\n",
    "# Creates training and test data loaders\n",
    "dl_train = DataLoader(ds_train, batch_size, shuffle)\n",
    "dl_test = DataLoader(ds_test, batch_size, shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gp_train(dl_train, dl_val, ps, sspace_sml, ffunction, log_path, selection_pressure, mutation_prob, xo_prob, has_elitism, allow_reproduction, seed=1, n_iter=3000, device='cpu',save_model=False, id=None):\n",
    "\n",
    "    pi_sml = SML(\n",
    "        sspace=sspace_sml,\n",
    "        ffunction=ffunction,\n",
    "        dl_train=dl_train, dl_test=dl_val,  # For the algorithm, the unseen is our validation!\n",
    "        n_jobs=8\n",
    "    )\n",
    "\n",
    "    mheuristic = GeneticAlgorithm(\n",
    "        pi=pi_sml,\n",
    "        initializer=grow,\n",
    "        selector=prm_tournament(pressure=selection_pressure),  #prm_tournament(pressure=selection_pressure)\n",
    "        crossover=swap_xo,\n",
    "        mutator=prm_subtree_mtn(initializer=prm_grow(sspace_sml)),\n",
    "        pop_size=ps,\n",
    "        p_m=mutation_prob,\n",
    "        p_c=xo_prob,\n",
    "        elitism=has_elitism,\n",
    "        reproduction=allow_reproduction,  # False = or xo or mutation\n",
    "        device=device,\n",
    "        seed=seed\n",
    "    )\n",
    "    mheuristic._initialize()\n",
    "\n",
    "    mheuristic.solve(\n",
    "        n_iter,\n",
    "        verbose=0, log=0, log_path=log_path,\n",
    "        test_elite=True\n",
    "    )\n",
    "    \n",
    "    if save_model:    \n",
    "        with open('models/GP/'+str(id)+'_GP.pkl', 'wb') as f:\n",
    "            pickle.dump(mheuristic, f)\n",
    "    \n",
    "    return mheuristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_2\n"
     ]
    }
   ],
   "source": [
    "m = gp_train(dl_train = dl_train, dl_val = dl_test, ps=ps, sspace_sml = sspace_sml, ffunction=ffunction, log_path='abc.csv',  selection_pressure=0.05, mutation_prob=0.2, xo_prob=0.8, has_elitism=True, allow_reproduction=True, seed=1, n_iter=3, device='cpu')\n",
    "m.best_sol.printTree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gp_cross_validation(X_train, y_train, kf, ps, sspace_sml, ffunction, log_path,  selection_pressure, mutation_prob, xo_prob, has_elitism, allow_reproduction, seed, n_iter, device, id=None, log=False):\n",
    "    results = []\n",
    "    feature_names = pd.read_csv('datamart/X_train_clipped_scaled.csv').columns\n",
    "    \n",
    "    if log:\n",
    "        name = 'logs/GP/' + f'{id}' + '_random_search.csv'\n",
    "        with open(name, 'w', newline='\\n') as csvfile:\n",
    "            w = csv.writer(csvfile, delimiter=';')\n",
    "            w.writerow(['id']+['fold']+['score'])\n",
    "            \n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(X_train)):\n",
    "        ds_train = TensorDataset(X_train[train_index], y_train[train_index])\n",
    "        ds_val = TensorDataset(X_train[val_index], y_train[val_index])\n",
    "\n",
    "        # Creates training and test data loaders\n",
    "        dl_train = DataLoader(ds_train, batch_size, shuffle)\n",
    "        dl_val = DataLoader(ds_val, batch_size, shuffle)\n",
    "\n",
    "        m = train_model(dl_train = dl_train, dl_val = dl_val, ps=ps, sspace_sml = sspace_sml, ffunction=ffunction, log_path=log_path,  selection_pressure=selection_pressure, mutation_prob=mutation_prob, xo_prob=xo_prob, has_elitism=has_elitism, allow_reproduction=allow_reproduction, seed=seed, n_iter=n_iter, device=device)\n",
    "        mse = evaluate_solution(m, X_train[val_index], y_train[val_index])\n",
    "        results.append(mse)\n",
    "        m.best_sol.printTree(feature_names=feature_names)\n",
    "        \n",
    "    avg_mse = np.mean(results)\n",
    "    print('cv_score:', avg_mse)\n",
    "    \n",
    "    return avg_mse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forage_kg_day\n",
      "forage_kg_day\n",
      "forage_kg_day\n",
      "forage_kg_day\n",
      "forage_kg_day\n",
      "forage_kg_day\n",
      "forage_kg_day\n",
      "forage_kg_day\n",
      "forage_kg_day\n",
      "forage_kg_day\n",
      "cv_score: 0.39562115557761046\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.39562115557761046"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = RepeatedKFold(n_splits=5, random_state=seed, n_repeats=2)\n",
    "gp_cross_validation(X_train, y_train, kf, ps=ps, sspace_sml = sspace_sml, ffunction = ffunction, log_path='abc.csv',  selection_pressure=0.05, mutation_prob=0.2, xo_prob=0.8, has_elitism=True, allow_reproduction=True, seed=1, n_iter=2, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[add, div, sub]\n",
      "sub( refusals_by_milking, -4.4250 )\n",
      "forage_kg_day\n",
      "forage_kg_day\n",
      "forage_kg_day\n",
      "forage_kg_day\n",
      "cv_score: 0.32519392122003526\n",
      "0.32519392122003526\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 44\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(name, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m csvfile:\n\u001b[0;32m     43\u001b[0m     w \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mwriter(csvfile, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 44\u001b[0m     w\u001b[38;5;241m.\u001b[39mwriterow([i]\u001b[38;5;241m+\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mmodel\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptimizer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39m[lr]\u001b[38;5;241m+\u001b[39m[weight_decay]\u001b[38;5;241m+\u001b[39m[batch_size]\u001b[38;5;241m+\u001b[39m[n_epochs]\u001b[38;5;241m+\u001b[39m[score])\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# if score < best_score:\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m#     best_score = score\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m#     print('Iteration '+ str(i))\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m#     test_score = float(test_score)\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m#     print(f'New best test score: {test_score}')\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "fsets = [function_map['add'],  function_map['mul'], function_map['div'],function_map['sub'], function_map['mean']] #,  function_map['mean']]\n",
    "constant_sets = [ERC(-1., 1.), ERC(-5., 5.), ERC(-10., 10.)]\n",
    "pss = [50, 100, 250, 500, 1000]\n",
    "p_constantss = [0.05, 0.1, 0.2, 0.3]\n",
    "max_init_depths = [2, 3, 4, 5, 6]\n",
    "max_depths = [5, 6, 7, 8, 9]\n",
    "selection_pressures = [0.05, 0.1, 0.2, 0.3, 0.4]\n",
    "mutatuion_probs = [0.05, 0.1, 0.15, 0.2, 0.5]\n",
    "xo_probs = [0.05, 0.1, 0.15, 0.2, 0.5]\n",
    "has_elitisms = [True, False]\n",
    "allow_reproductions = [True, False]\n",
    "n_iters = [50, 100, 250, 500, 1000]\n",
    "ffunction = Ffunctions('rmse')\n",
    "kf = RepeatedKFold(n_splits=5, random_state=seed, n_repeats=1)\n",
    "\n",
    "best_score = np.inf\n",
    "\n",
    "name = 'logs/GP/' + 'random_search_total' + '.csv'\n",
    "with open(name, 'w', newline='\\n') as csvfile:\n",
    "    w = csv.writer(csvfile, delimiter=';')\n",
    "    w.writerow(['id']+['fset']+['constant_set']+['ps']+['p_constants']+['max_init_depth']+['max_depth']+['selection_pressure']+['mutation_prob']+['xo_prob']+['has_elitism']+['allow_reproduction']+['n_iter']+['score'])\n",
    "\n",
    "\n",
    "for i in range(200):\n",
    "\n",
    "    total_batches = 1\n",
    "    batch_size = X_train.shape[0]\n",
    "    \n",
    "    fset = random.sample(fsets, random.randint(1, len(fsets)))\n",
    "    print(fset)\n",
    "    constant_set = random.choice(constant_sets)\n",
    "    ps = random.choice(pss)\n",
    "    p_constants = random.choice(p_constantss)\n",
    "    max_init_depth = random.choice(max_init_depths)\n",
    "    max_depth = random.choice(max_depths)\n",
    "    selection_pressure = random.choice(selection_pressures)\n",
    "    mutation_prob = random.choice(mutatuion_probs)\n",
    "    xo_prob = random.choice(xo_probs)\n",
    "    has_elitism = random.choice(has_elitisms)\n",
    "    allow_reproduction = random.choice(allow_reproductions)\n",
    "    n_iter = random.choice(n_iters)\n",
    "\n",
    "\n",
    "    sspace_sml = {\n",
    "        'n_dims': X_train.shape[1],\n",
    "        'function_set': fset, 'constant_set': constant_set,\n",
    "        'p_constants': p_constants,\n",
    "        'max_init_depth': max_init_depth,\n",
    "        'max_depth': max_depth, \n",
    "        'n_batches': total_batches,\n",
    "        'device': device\n",
    "    }\n",
    "    score = gp_cross_validation(X_train, y_train, kf, ps=ps, sspace_sml = sspace_sml, ffunction=ffunction, log_path='abc.csv',  selection_pressure=selection_pressure, mutation_prob=mutation_prob, xo_prob=xo_prob, has_elitism=has_elitism, allow_reproduction=allow_reproduction, seed=1, n_iter=n_iter, device='cpu')\n",
    "    print(score)\n",
    "    \n",
    "    \n",
    "    name = 'logs/GP/' + 'random_search_total' + '.csv'\n",
    "    with open(name, 'a', newline='\\n') as csvfile:\n",
    "        w = csv.writer(csvfile, delimiter=';')\n",
    "        w.writerow([i]+[fset]+[constant_set]+[ps]+[p_constants]+[max_init_depth]+[max_depth]+[selection_pressure]+[mutation_prob]+[xo_prob]+[has_elitism]+[allow_reproduction]+[n_iter]+[score])\n",
    "    \n",
    "    if score < best_score:\n",
    "        best_score = score\n",
    "        print('Iteration '+ str(i))\n",
    "        print(f'New best validation score: {best_score}')\n",
    "        \n",
    "        gp_train(dl_train = dl_train, dl_val = dl_test, ps=ps, sspace_sml = sspace_sml, ffunction=ffunction, log_path='abc.csv',  selection_pressure=0.05, mutation_prob=0.2, xo_prob=0.8, has_elitism=True, allow_reproduction=True, seed=1, n_iter=3, device='cpu', log=True, id=i)\n",
    "        model = pickle.load(open('models/NN/' + str(i) + '_NN.pkl', 'rb'))\n",
    "        y_test_pred = model(X_test)\n",
    "        test_score = loss_fn(y_test_pred, y_test)\n",
    "        test_score = float(test_score)\n",
    "        print(f'New best test score: {test_score}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
